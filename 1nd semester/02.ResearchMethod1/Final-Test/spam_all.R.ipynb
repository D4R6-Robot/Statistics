{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data package install\n",
    "# install.packages(c('e1071', 'tree', 'randomForest', 'nnet', 'kernlab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)        # https://www.rdocumentation.org/packages/e1071/versions/1.7-2\n",
    "library(tree)         # https://www.rdocumentation.org/pack/tree/versions/1.0-40\n",
    "library(randomForest) # https://www.rdocumentation.org/packages/randomForest/versions/4.6-14\n",
    "library(nnet)         # https://www.rdocumentation.org/packages/nnet/versions/7.3-12\n",
    "library(kernlab)      # https://www.rdocumentation.org/packages/kernlab/versions/0.9-27\n",
    "\n",
    "# 예측 된 값이 얼마나 잘 적합 했는지 ROC Curve 를 그리고 그 면적의 Area Under the Curve 를 구해서 잘 적합 되는지 본다.\n",
    "library('ROCR')           # https://www.rdocumentation.org/packages/ROCR/versions/1.0-7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data(spam)\n",
    "n <- nrow(spam)       # int 4601 obws\n",
    "p <- ncol(spam)       # int 58 variables\n",
    "\n",
    "x <- scale(spam[,-p])     # Scaling and Centering of Matrix-like Objects\n",
    "                          # Large matrix : 4601 * 57 = 262,257\n",
    "y <- as.factor(spam[,p])  # \"type\" : spam, nonsapm\n",
    "\n",
    "set.seed(1)           # seed 를 1로 고정.\n",
    "index <- sample(n)    # 4601 의 데이터를 shuffle\n",
    "\n",
    "n.tr <- 500                     # n.tr : 500 으로 조정\n",
    "\n",
    "# train, test                   # x index\n",
    "x.tr <- x[index[ (1:n.tr)], ]   # (1:n.tr) : 1 ~ 500\n",
    "x.ts <- x[index[-(1:n.tr)], ]   # -(1:n.tr) : -1 ~ -500 # int 배열 x 에서[1 ~ 500] 데이터를 뺀 데이터.\n",
    "\n",
    "# train, test                   # y index\n",
    "y.tr <- y[index[ (1:n.tr)]]     # (1:n.tr) : 1 ~ 500\n",
    "y.ts <- y[index[-(1:n.tr)]]     # -(1:n.tr) : -1 ~ -500 # int 배열 x 에서[1 ~ 500] 데이터를 뺀 데이터.\n",
    "\n",
    "tr <- data.frame(x.tr, y.tr)    # train 데이터는 data frame 으로 type casting\n",
    "ts <- data.frame(x.ts, y.ts)    # test 데이터는 data frame 으로 type casting\n",
    "names(tr) <- names(spam)        # spam 에 있는 header 변수 이름을 train 의 해더로 교체.\n",
    "                                # 마지막 변수 \"y.tr\" -> \"type\" 으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.723333909898342"
      ],
      "text/latex": [
       "0.723333909898342"
      ],
      "text/markdown": [
       "0.723333909898342"
      ],
      "text/plain": [
       "[1] 0.7233339"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Naieve Bayes\n",
    "\n",
    "# https://www.rdocumentation.org/packages/naivebayes/versions/0.9.6\n",
    "# apriori 알고리즘 , 참고 url\n",
    "# https://en.wikipedia.org/wiki/Apriori_algorithm\n",
    "# https://www.r-bloggers.com/implementing-apriori-algorithm-in-r/\n",
    "nb <- naiveBayes(type ~ ., data = tr) # type 을 반응 변수로 두고, 모두를 설명 변수로 시작.\n",
    "\n",
    "nb.y.ts <- predict(nb, ts[,-p])       # ts 의 58 번째 열 y.ts 삭제.\n",
    "                                      # naems(tr) 로 train set 만 y.tr > type 로 바꿈. ts 는 바꾸지 않음.\n",
    "                                      # 하기 내용으로 예측된 nb.y.ts 와 실제 맞는 ts[,p] = ts[p]$y.ts 를 비교 한다.\n",
    "\n",
    "# https://www.rdocumentation.org/packages/ROCR/versions/1.0-7/topics/prediction\n",
    "pred_naieve <- prediction(as.numeric(nb.y.ts), as.numeric(ts[p]$y.ts))\n",
    "# https://www.rdocumentation.org/packages/ROCR/versions/1.0-1/topics/performance\n",
    "# Naieve Bayes 방법으로 활용된 prediction 값으로 auc 값을 확인한다.\n",
    "result_naieve <- performance(pred_naieve, \"auc\")@y.values[[1]]\n",
    "result_naieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"glm.fit: fitted probabilities numerically 0 or 1 occurred\""
     ]
    },
    {
     "data": {
      "text/html": [
       "0.881619946623705"
      ],
      "text/latex": [
       "0.881619946623705"
      ],
      "text/markdown": [
       "0.881619946623705"
      ],
      "text/plain": [
       "[1] 0.8816199"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# https://www.rdocumentation.org/packages/stats/versions/3.6.0/topics/glm\n",
    "# binomial 로 주는 것이 logistic regression 이다.\n",
    "# multinomial 로는 다른 패키지를 사용 해야 한다.\n",
    "logit <- glm(type ~ ., data = tr, family=\"binomial\")\n",
    "logit.prob <- predict(logit, ts[,-p], type = \"response\")    # training 된 logit 모델을 ts 의 58 번째 열 y.ts 삭제 후 predict 시작.\n",
    "logit.y.ts <- ifelse(logit.prob > 0.5, \"spam\", \"nonspam\")   # 테스트한 데이터를 기준으로 0.5 기준으로 spam , nospam 으로 나눈다.\n",
    "\n",
    "# named vector 를 기존의 값(ts[p]$y.ts) 과 비교하기 위해서 factor 로 형 변환을 한다. 이것은 기억하자.\n",
    "factor_logic <- as.factor(logit.y.ts)\n",
    "# 하기 내용으로 예측된 factor_logic 와 실제 맞는 ts[p]$y.ts 를 비교 한다.\n",
    "pred_logit <- prediction(as.numeric(factor_logic), as.numeric(ts[p]$y.ts)) \n",
    "\n",
    "# pred_logit 의 AUC 를 보고 모델의 적합성과 얼마나 좋은지 판단 한다.\n",
    "result_logit <- performance(pred_logit, \"auc\")@y.values[[1]]\n",
    "result_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.873813513952707"
      ],
      "text/latex": [
       "0.873813513952707"
      ],
      "text/markdown": [
       "0.873813513952707"
      ],
      "text/plain": [
       "[1] 0.8738135"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification Tree\n",
    "# https://www.rdocumentation.org/packages/tree/versions/1.0-40\n",
    "# type 을 반응 변수로 두고, 남은 전체를 설명변수로 tree 모델로 fit 시킨다.\n",
    "tree.sg <- tree(type ~ ., data = tr)\n",
    "# fit 된 모델의 cross-validation 을 적용한다.\n",
    "tree.cv <- cv.tree(tree.sg)\n",
    "# pruning 기법으로 tree 의 가지를 쳐서 제한을 둔다.\n",
    "# cross-validation 의 deviance 의 값으로 가장 낮은 값의 index 를 선택하여, 거기 까지만 pruning 한다.\n",
    "# https://www.rdocumentation.org/packages/tree/versions/1.0-40/topics/prune.tree\n",
    "tree.prune <- prune.tree(tree.sg, best = tree.cv$size[which.min(tree.cv$dev)])\n",
    "# pruning 한 모델을 가지고 test set 을 넣어 예측한다.\n",
    "tree.pred <- predict(tree.prune, newdata = ts)\n",
    "# 예측한 nonspam, spam 두 값으로 비교하여 각 행의 값을 고른다.\n",
    "tree.sg.y.ts <- ifelse(tree.pred[,1] > tree.pred[,2], \"nonspam\", \"spam\")\n",
    "\n",
    "# named vector 를 기존의 값(ts[p]$y.ts) 과 비교하기 위해서 factor 로 형 변환을 한다. 이것은 기억하자.\n",
    "factor_tree <- as.factor(tree.sg.y.ts)\n",
    "# 하기 내용으로 예측된 factor_tree 와 실제 맞는 ts[p]$y.ts 를 비교 한다.\n",
    "pred_tree <- prediction(as.numeric(factor_tree), as.numeric(ts[p]$y.ts))\n",
    "\n",
    "# pred_tree 의 AUC 를 보고 모델의 적합성과 얼마나 좋은지 판단 한다.\n",
    "result_tree <- performance(pred_tree, \"auc\")@y.values[[1]]\n",
    "result_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.925258606852783"
      ],
      "text/latex": [
       "0.925258606852783"
      ],
      "text/markdown": [
       "0.925258606852783"
      ],
      "text/plain": [
       "[1] 0.9252586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RandomForest\n",
    "# https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest\n",
    "# type 을 반응 변수로 두고, 남은 전체를 설명변수로 randomForest 모델로 fit 시킨다.\n",
    "ranf <- randomForest(type ~ ., data = tr)\n",
    "# fitting 된 모델을 가지고 test set 을 넣어 예측한다.\n",
    "ranf.y.ts <- predict(ranf, newdata = ts)\n",
    "\n",
    "# 하기 내용으로 예측된 ranf.y.ts 와 실제 맞는 ts[p]$y.ts 를 비교 한다.\n",
    "pred_rf <- prediction(as.numeric(ranf.y.ts), as.numeric(ts[p]$y.ts))\n",
    "# pred_tree 의 AUC 를 보고 모델의 적합성과 얼마나 좋은지 판단 한다.\n",
    "result_rf <- performance(pred_rf, \"auc\")@y.values[[1]]\n",
    "result_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.893413774952222"
      ],
      "text/latex": [
       "0.893413774952222"
      ],
      "text/markdown": [
       "0.893413774952222"
      ],
      "text/plain": [
       "[1] 0.8934138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gaussian Kernel SVM\n",
    "C.grid <- (2)^(-5:10) # SVM 은 C가 조율 모수의 역할을 한다.\n",
    "# https://www.rdocumentation.org/packages/e1071/versions/1.7-2/topics/tune\n",
    "# tune.svm 으로 kernel 의 default 설정은 \"radial\" 이다. RBF kernel = Gaussian kernel.\n",
    "# 정한 gamma, cost 를 가지고 svm tuning 을 시작한다.\n",
    "tune.obj <- tune.svm(type ~ ., data = tr, gamma = 1/p, cost = C.grid) \n",
    "\n",
    "# 가장 좋은 조율 모수 C 정하고\n",
    "best.C <- tune.obj$best.model$cost \n",
    "# type 을 반응 변수로 두고, 남은 전체를 설명 변수로 svm 모델로 fit 시킨다.\n",
    "svm.gs <- svm(type ~., gamma = 1/p, cost = best.C, data = tr) \n",
    "# fitting 된 모델을 가지고 test set 을 넣어 예측한다.\n",
    "svm.gs.y.ts <- predict(svm.gs, ts)\n",
    "\n",
    "# 하기 내용으로 예측된 svm.gs.y.ts 와 실제 맞는 ts[p]$y.ts 를 비교 한다.\n",
    "pred_svm_gs <- prediction(as.numeric(svm.gs.y.ts), as.numeric(ts[p]$y.ts))\n",
    "# pred_svm_gs 의 AUC 를 보고 모델의 적합성과 얼마나 좋은지 판단 한다.\n",
    "result_svm_gs <- performance(pred_svm_gs, \"auc\")@y.values[[1]]\n",
    "result_svm_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.902972956941062"
      ],
      "text/latex": [
       "0.902972956941062"
      ],
      "text/markdown": [
       "0.902972956941062"
      ],
      "text/plain": [
       "[1] 0.902973"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Linear Kernel SVM\n",
    "C.grid <- (2)^(-5:10) # SVM 은 C가 조율 모수의 역할을 한다.\n",
    "# https://www.rdocumentation.org/packages/e1071/versions/1.7-1/topics/svm 의 kernel 체크.\n",
    "# tune.svm 으로 kernel 옵션을 'linear' 로 변경 하고, 정한 cost 를 가지고 svm tuning 을 시작한다.\n",
    "tune.obj <- tune.svm(type ~ ., data = tr, kernel = \"linear\", cost = C.grid)\n",
    "\n",
    "# 가장 좋은 조율 모수 C 정하고\n",
    "best.C <- tune.obj$best.model$cost\n",
    "# type 을 반응 변수로 두고, 남은 전체를 설명 변수로 svm 모델로 fit 시킨다.\n",
    "svm.ln <- svm(type ~ ., data = tr, kernel = \"linear\", cost = best.C)\n",
    "# fitting 된 모델을 가지고 test set 을 넣어 예측한다.\n",
    "svm.ln.y.ts <- predict(svm.ln, ts) \n",
    "\n",
    "# 하기 내용으로 예측된 svm.ln.y.ts 와 실제 맞는 ts[p]$y.ts 를 비교 한다.\n",
    "pred_svm_ln <- prediction(as.numeric(svm.ln.y.ts), as.numeric(ts[p]$y.ts))\n",
    "# pred_svm_ln 의 AUC 를 보고 모델의 적합성과 얼마나 좋은지 판단 한다.\n",
    "result_svm_ln <- performance(pred_svm_ln, \"auc\")@y.values[[1]]\n",
    "result_svm_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  296\n",
      "initial  value 337.276842 \n",
      "iter  10 value 43.404071\n",
      "iter  20 value 18.774851\n",
      "iter  30 value 6.551044\n",
      "iter  40 value 2.677034\n",
      "iter  50 value 1.943315\n",
      "iter  60 value 1.927098\n",
      "iter  70 value 0.572447\n",
      "iter  80 value 0.048699\n",
      "iter  90 value 0.040685\n",
      "iter 100 value 0.026658\n",
      "iter 110 value 0.016686\n",
      "iter 120 value 0.009049\n",
      "iter 130 value 0.004496\n",
      "iter 140 value 0.002300\n",
      "iter 150 value 0.001154\n",
      "iter 160 value 0.000818\n",
      "iter 170 value 0.000481\n",
      "iter 180 value 0.000340\n",
      "iter 190 value 0.000199\n",
      "iter 200 value 0.000151\n",
      "final  value 0.000097 \n",
      "converged\n",
      " chr [1:4101] \"nonspam\" \"nonspam\" \"nonspam\" \"nonspam\" \"nonspam\" \"nonspam\" ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.903486133029997"
      ],
      "text/latex": [
       "0.903486133029997"
      ],
      "text/markdown": [
       "0.903486133029997"
      ],
      "text/plain": [
       "[1] 0.9034861"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# neural network\n",
    "# https://www.rdocumentation.org/packages/nnet/versions/7.3-12/topics/nnet\n",
    "# maxit - maximum number of iterations. Default 100.\n",
    "# size - number of units in the hidden layer. Can be zero if there are skip-layer units.\n",
    "# type 을 반응변수로, 나머지를 설명변수로 두고, hidden layer 를 5개 두고 iteration 을 500 준다.\n",
    "nrnet <- nnet(type ~., data = tr, size = 5, maxit = 500)\n",
    "# type 은 class 로 범주형의 타입으로 두고 predict 을 한다.\n",
    "nrnet.y.ts <- predict(nrnet, ts[,-p], type = \"class\") \n",
    "\n",
    "# char array 를 기존의 값(ts[p]$y.ts) 과 비교하기 위해서 factor 로 형 변환을 한다. 이것은 기억하자.\n",
    "factor_nrnet <- as.factor(nrnet.y.ts)\n",
    "\n",
    "# 하기 내용으로 예측된 factor_nrnet 와 실제 맞는 ts[p]$y.ts 를 비교 한다.\n",
    "pred_nrnet <- prediction(as.numeric(factor_nrnet), as.numeric(ts[p]$y.ts))\n",
    "# pred_svm_ln 의 AUC 를 보고 모델의 적합성과 얼마나 좋은지 판단 한다.\n",
    "result_nrnet <- performance(pred_nrnet, \"auc\")@y.values[[1]]\n",
    "result_nrnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>method</th><th scope=col>auc</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Naieve Bayes  </td><td>0.7233339     </td></tr>\n",
       "\t<tr><td>Logistic      </td><td>0.8816199     </td></tr>\n",
       "\t<tr><td>Tree          </td><td>0.8738135     </td></tr>\n",
       "\t<tr><td>RandomForest  </td><td>0.9252586     </td></tr>\n",
       "\t<tr><td>Gaussian SVM  </td><td>0.8934138     </td></tr>\n",
       "\t<tr><td>Linear SVM    </td><td>0.9029730     </td></tr>\n",
       "\t<tr><td>Neural Network</td><td>0.8949491     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " method & auc\\\\\n",
       "\\hline\n",
       "\t Naieve Bayes   & 0.7233339     \\\\\n",
       "\t Logistic       & 0.8816199     \\\\\n",
       "\t Tree           & 0.8738135     \\\\\n",
       "\t RandomForest   & 0.9252586     \\\\\n",
       "\t Gaussian SVM   & 0.8934138     \\\\\n",
       "\t Linear SVM     & 0.9029730     \\\\\n",
       "\t Neural Network & 0.8949491     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "method | auc | \n",
       "|---|---|---|---|---|---|---|\n",
       "| Naieve Bayes   | 0.7233339      | \n",
       "| Logistic       | 0.8816199      | \n",
       "| Tree           | 0.8738135      | \n",
       "| RandomForest   | 0.9252586      | \n",
       "| Gaussian SVM   | 0.8934138      | \n",
       "| Linear SVM     | 0.9029730      | \n",
       "| Neural Network | 0.8949491      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  method         auc      \n",
       "1 Naieve Bayes   0.7233339\n",
       "2 Logistic       0.8816199\n",
       "3 Tree           0.8738135\n",
       "4 RandomForest   0.9252586\n",
       "5 Gaussian SVM   0.8934138\n",
       "6 Linear SVM     0.9029730\n",
       "7 Neural Network 0.8949491"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 모델 방법의 result 종류를 가지고 data frame 을 만든다.\n",
    "data.frame(method=c('Naieve Bayes','Logistic','Tree','RandomForest','Gaussian SVM', 'Linear SVM', 'Neural Network'),\n",
    "           auc=c(result_naieve,\n",
    "                 result_logit,\n",
    "                 result_tree,\n",
    "                 result_rf,\n",
    "                 result_svm_gs,\n",
    "                 result_svm_ln,\n",
    "                 result_nrnet\n",
    "                 ))\n",
    "# RandomForest 가 제일 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAQlBMVEUAAAAAAP8AzQAA//9N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\ngg==",
      "text/plain": [
       "Plot with title \"ROC Curve\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 각 모델 의 ROC Curve 를 그래프화 시켜서 Visualization 한다.\n",
    "# https://www.rdocumentation.org/packages/mlr/versions/2.14.0/topics/performance\n",
    "# [y-axis] measure : true positive rate, [x-axis] x.measure : false positive rate\n",
    "perf_naieve <- performance(pred_naieve, measure='tpr',x.measure='fpr')\n",
    "perf_logit <- performance(pred_logit, measure='tpr',x.measure='fpr')\n",
    "perf_tree <- performance(pred_tree, measure='tpr',x.measure='fpr')\n",
    "perf_rf <- performance(pred_rf, measure='tpr',x.measure='fpr')\n",
    "perf_svm_gs <- performance(pred_svm_gs, measure='tpr',x.measure='fpr')\n",
    "perf_svm_ln <- performance(pred_svm_ln, measure='tpr',x.measure='fpr')\n",
    "perf_nrnet <- performance(pred_nrnet, measure='tpr',x.measure='fpr')\n",
    "\n",
    "# 색 별로 ROC Curve 를 그린다.\n",
    "# https://www.rdocumentation.org/packages/graphics/versions/3.6.0/topics/plot\n",
    "plot(perf_naieve, col='black', main=\"ROC Curve\")\n",
    "plot(perf_logit, add=TRUE, col='blue')\n",
    "plot(perf_tree, add=TRUE, col='darkviolet')\n",
    "plot(perf_rf, add=TRUE, col='red')\n",
    "plot(perf_svm_gs, add=TRUE, col='cyan')\n",
    "plot(perf_svm_ln, add=TRUE, col='green3')\n",
    "plot(perf_nrnet, add=TRUE, col='magenta4')\n",
    "\n",
    "# https://www.rdocumentation.org/packages/graphics/versions/3.6.0/topics/legend\n",
    "# legend 사각형을 bottom 의 오른쪽에 설명을 적는다.\n",
    "legend('bottomright', inset=.1,\n",
    "       legend=c(\"Naieve\", \"Logit\", \"TREE\", \"RF\", \"SVM_GS\", \"SVM_LN\", \"NeuralNet\"),\n",
    "       col=c('black', 'blue', 'darkviolet', 'red', 'cyan', 'green3', 'magenta4'), lty=1, lwd=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결론. Random Forest 가 수치가 제일 좋다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
